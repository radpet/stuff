{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from util import labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = [50000, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vects_1_2 = [CountVectorizer(ngram_range=(1,2), max_features=x, stop_words='english') for x in max_features]\n",
    "tf_idf_vects_1_1 = [TfidfVectorizer(max_features=x, stop_words='english') for x in max_features]\n",
    "tf_idf_vects_1_2 = [TfidfVectorizer(max_features=x, ngram_range=(1,2), stop_words='english') for x in max_features]\n",
    "# vects = tf_idf_vects_1_1 + count_vects_1_2\n",
    "vects = tf_idf_vects_1_1 + tf_idf_vects_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1,1.2,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting vectorizer TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "Fitted vectorizer\n",
      "Now finding best model for toxic\n",
      "Found best model with roc=0.9699397257007154\n",
      "################################################################################\n",
      "Now finding best model for severe_toxic\n",
      "Found best model with roc=0.9836755439466964\n",
      "################################################################################\n",
      "Now finding best model for obscene\n",
      "Found best model with roc=0.9852337220912831\n",
      "################################################################################\n",
      "Now finding best model for threat\n",
      "Found best model with roc=0.9813835353638687\n",
      "################################################################################\n",
      "Now finding best model for insult\n",
      "Found best model with roc=0.9765421432703197\n",
      "################################################################################\n",
      "Now finding best model for identity_hate\n",
      "Found best model with roc=0.9733788035261526\n",
      "################################################################################\n",
      "Fitting vectorizer TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "Fitted vectorizer\n",
      "Now finding best model for toxic\n",
      "Found best model with roc=0.9699397257007154\n",
      "################################################################################\n",
      "Now finding best model for severe_toxic\n",
      "Found best model with roc=0.9842230262267296\n",
      "################################################################################\n",
      "Now finding best model for obscene\n",
      "Found best model with roc=0.9855908335916193\n",
      "################################################################################\n",
      "Now finding best model for threat\n",
      "Found best model with roc=0.9821217293243816\n",
      "################################################################################\n",
      "Now finding best model for insult\n",
      "Found best model with roc=0.9766866243824314\n",
      "################################################################################\n",
      "Now finding best model for identity_hate\n",
      "Found best model with roc=0.9745756589450332\n",
      "################################################################################\n",
      "Fitting vectorizer TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "Fitted vectorizer\n",
      "Now finding best model for toxic\n",
      "Found best model with roc=0.9699397257007154\n",
      "################################################################################\n",
      "Now finding best model for severe_toxic\n",
      "Found best model with roc=0.9842230262267296\n",
      "################################################################################\n",
      "Now finding best model for obscene\n",
      "Found best model with roc=0.9855908335916193\n",
      "################################################################################\n",
      "Now finding best model for threat\n",
      "Found best model with roc=0.9833088197590685\n",
      "################################################################################\n",
      "Now finding best model for insult\n",
      "Found best model with roc=0.9766866243824314\n",
      "################################################################################\n",
      "Now finding best model for identity_hate\n",
      "Found best model with roc=0.9745756589450332\n",
      "################################################################################\n",
      "Fitting vectorizer TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "Fitted vectorizer\n",
      "Now finding best model for toxic\n",
      "Found best model with roc=0.9706784477661271\n",
      "################################################################################\n",
      "Now finding best model for severe_toxic\n",
      "Found best model with roc=0.9856702080585757\n",
      "################################################################################\n",
      "Now finding best model for obscene\n",
      "Found best model with roc=0.9858329200429503\n",
      "################################################################################\n",
      "Now finding best model for threat\n",
      "Found best model with roc=0.9837471287271651\n",
      "################################################################################\n",
      "Now finding best model for insult\n",
      "Found best model with roc=0.976818177958938\n",
      "################################################################################\n",
      "Now finding best model for identity_hate\n",
      "Found best model with roc=0.9752328439093448\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "for vect in vects:\n",
    "    print('Fitting vectorizer {}'.format(vect))\n",
    "    fitted = vect.fit(train['comment_text'].append(test['comment_text']))\n",
    "    \n",
    "    train_vect = vect.transform(train['comment_text'])\n",
    "    print('Fitted vectorizer')\n",
    "    \n",
    "    for label in labels:\n",
    "        print('Now finding best model for {}'.format(label))\n",
    "        \n",
    "        for c in C:\n",
    "            model = LogisticRegression(C=c, class_weight='balanced')\n",
    "            score = cross_val_score(model,X=train_vect, y=train[label], scoring='roc_auc', cv=5, n_jobs=-1).mean()\n",
    "            if label not in best:\n",
    "                best[label] = {\n",
    "                    'score' : 0\n",
    "                }\n",
    "                \n",
    "            if best[label]['score']  < score:\n",
    "                best[label] = {\n",
    "                    'score':score,\n",
    "                    'model':model,\n",
    "                    'vect': vect,\n",
    "                    'C':c\n",
    "                }\n",
    "                \n",
    "        print('Found best model with roc={}'.format(best[label]['score']))\n",
    "        print('#'*80)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for toxic is {'C': 5, 'score': 0.97067844776612711, 'model': LogisticRegression(C=5, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "################################################################################\n",
      "Best model for severe_toxic is {'C': 1, 'score': 0.98567020805857575, 'model': LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "################################################################################\n",
      "Best model for obscene is {'C': 5, 'score': 0.98583292004295031, 'model': LogisticRegression(C=5, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "################################################################################\n",
      "Best model for threat is {'C': 5, 'score': 0.98374712872716508, 'model': LogisticRegression(C=5, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "################################################################################\n",
      "Best model for insult is {'C': 5, 'score': 0.97681817795893799, 'model': LogisticRegression(C=5, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "################################################################################\n",
      "Best model for identity_hate is {'C': 1.2, 'score': 0.97523284390934484, 'model': LogisticRegression(C=1.2, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print('Best model for {} is {}'.format(label, best[label]))\n",
    "    print('#'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds={}\n",
    "for label in labels:\n",
    "    test_vect = best[label]['vect'].transform(test['comment_text'])\n",
    "    train_vect = best[label]['vect'].transform(train['comment_text'])\n",
    "    model = best[label]['model'].fit(train_vect, train[label])\n",
    "    preds[label] = model.predict_proba(test_vect)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identity_hate': array([ 0.76865995,  0.0317534 ,  0.04127174, ...,  0.02257207,\n",
       "         0.11449891,  0.09996913]),\n",
       " 'insult': array([ 0.985198  ,  0.0153697 ,  0.04427762, ...,  0.0160138 ,\n",
       "         0.02726532,  0.85729073]),\n",
       " 'obscene': array([ 0.99932671,  0.00902373,  0.03290908, ...,  0.01556612,\n",
       "         0.02608201,  0.9639512 ]),\n",
       " 'severe_toxic': array([ 0.70404019,  0.02460571,  0.03418322, ...,  0.02202048,\n",
       "         0.02050449,  0.02859875]),\n",
       " 'threat': array([ 0.10164643,  0.00431405,  0.00414325, ...,  0.00320748,\n",
       "         0.00657337,  0.01017341]),\n",
       " 'toxic': array([ 0.99935448,  0.01540551,  0.08006981, ...,  0.02047427,\n",
       "         0.03399454,  0.99549984])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame(preds, index=test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>0.768660</td>\n",
       "      <td>0.985198</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.704040</td>\n",
       "      <td>0.101646</td>\n",
       "      <td>0.999354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>0.031753</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.024606</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.015406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>0.041272</td>\n",
       "      <td>0.044278</td>\n",
       "      <td>0.032909</td>\n",
       "      <td>0.034183</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.080070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.013951</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.006268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>0.021874</td>\n",
       "      <td>0.036460</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.064843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  identity_hate    insult   obscene  severe_toxic    threat  \\\n",
       "id                                                                            \n",
       "00001cee341fdb12       0.768660  0.985198  0.999327      0.704040  0.101646   \n",
       "0000247867823ef7       0.031753  0.015370  0.009024      0.024606  0.004314   \n",
       "00013b17ad220c46       0.041272  0.044278  0.032909      0.034183  0.004143   \n",
       "00017563c3f7919a       0.006561  0.004518  0.004212      0.013951  0.002284   \n",
       "00017695ad8997eb       0.021874  0.036460  0.023301      0.024765  0.005588   \n",
       "\n",
       "                     toxic  \n",
       "id                          \n",
       "00001cee341fdb12  0.999354  \n",
       "0000247867823ef7  0.015406  \n",
       "00013b17ad220c46  0.080070  \n",
       "00017563c3f7919a  0.006268  \n",
       "00017695ad8997eb  0.064843  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('./submission-tmp/logistic_bl.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
